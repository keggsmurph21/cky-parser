import argparse
import pickle
from collections import defaultdict
from sys import stderr

def slugify(array):
    array = [s for s in array if s != '|']
    return '~~~'.join(array)

def deslugify(string):
    return string.split('~~~')


class _Rule:
    
    def __init__(self, name):

        self.name = name
        self.parents = []
        self.terminals = []
        self.nonterminals = []

    def add_parent(self, parent):

        if parent not in self.parents:
            self.parents.append(parent)

    def remove_parent(self, parent):

        if parent not in self.parents:
            print(parent, self)
            raise KeyError()

        self.parents = [ p for p in self.parents if p != parent ]

    def add_terminal(self, terminals):

        for terminal in terminals:
            if terminal not in self.terminals and terminal != ' ' and terminal != '|':
                self.terminals.append(terminal)

    def add_nonterminal(self, nonterminal):

        nonterminal = slugify(nonterminal)
        if nonterminal not in self.nonterminals:
            self.nonterminals.append(nonterminal)

    def replace_nonterminal(self, original_nt, to_replace, replace_with):

        #print(self)
        #print(original_nt, to_replace, replace_with)

        new_nt = []
        for original_tag in original_nt:
            
            if original_tag == to_replace:
                for new_tag in replace_with:

                    new_nt.append(new_tag)

            else:
                new_nt.append(original_tag)
            
        self.add_nonterminal(new_nt)

        #print(new_nt) 
        #print(self)

    def remove_nonterminal(self, nonterminal):

        nonterminal = slugify(nonterminal)

        if nonterminal not in self.nonterminals:
            print(nonterminal, self)
            raise KeyError()

        self.nonterminals = [ nt for nt in self.nonterminals if nt != nonterminal ]

    def get_nonterminals(self):

        return [ deslugify(nt) for nt in self.nonterminals ]

    def has_child(self, nonterminal):

        for rule in self.get_nonterminals():
            if nonterminal in rule:
                return True

        return False

    def is_mixed(self):
        return len(self.terminals) and len(self.nonterminals)

    def is_unit(self):

        for nonterminal in self.get_nonterminals():
            if len(nonterminal) == 1:
                return True

        return False

    def is_long(self):

        for nonterminal in self.get_nonterminals():
            if len(nonterminal) > 2:
                return True

        return False



def slug(src, tars):
    
    items = [src] + list(tars)
    return slugify(items)

def unslug(string):

    items = deslugify(string)
    return (items[0], items[1:])

def make_CNF(g_old):

    if g_old.is_CNF():
        return g_old

    #g_old.print()
    g_new = Grammar()
    units = set()

    reverse_lookup = defaultdict(set)
    tokens = defaultdict(set)

    for rule in g_old.rules:

        if rule.is_terminal:
            g_new.add_rule(rule.src, rule.tars, True)

            '''
            for tar in rule.tars:
                tokens[rule.src].add(tar)'''

        elif not rule.is_unit():

            for tar in rule.tars:
                reverse_lookup[tar].add(rule)
            g_new.add_rule(rule.src, rule.tars, False)

        else:
            units.add(rule)

    #print('units', units)
    #for unit in tqdm(units, desc=f'removing {len(units)} units'):
        #print(unit, reverse_lookup[unit.src])
        #for rule in reverse_lookup[unit.src]:
    
    #print()
    #g_old.print()
    #print()

    desc = f'removing {len(units)} units'
    for (i,rule) in enumerate(g_new.rules):
        #stderr.write(f'\r{i+1} of {len(g_new.rules)}')
    #for rule in tqdm(g_new.rules, desc=desc):

        tars = set(rule.tars)

        for unit in units:

            if unit.src in tars:#if rule.has_targeIt(unit.src):
                
                new_tars = []
                for tar in rule.tars:
                    
                    if tar == unit.src:
                        new_tars.append(unit.tars[0])
                    else:
                        new_tars.append(tar)

                g_new.rules[i] = Rule(rule.src, new_tars, False)
                #g_new.add_rule(rule.src, new_tars, False)

    #print()
    #g_new.print()
    #print()

    g_old = g_new
    g_new = Grammar()

    all_tags = set()
    for rule in g_old.rules:
        all_tags.add(rule.src)

    #print(all_tags)
    for rule in g_old.rules:
    
        is_valid = True
        if not rule.is_terminal:
            for tar in rule.tars:
                is_valid = (is_valid and tar in all_tags)

        if is_valid:
            #print('add', rule.src)
            g_new.add_rule(rule.src, rule.tars, False)

        #else:
            #print('invalid', rule)

    #print()
    #g_new.print()
    #print()

    g_old = g_new
    g_new = Grammar()

    for rule in g_old.rules:

        if rule.is_terminal:
            g_new.add_rule(rule.src, rule.tars, True)
        elif not rule.is_long():
            #print('ok', rule)
            g_new.add_rule(rule.src, rule.tars, False)
        else:

            #print('long', rule)
            src = rule.src
            head = rule.tars[0]
            tail = rule.tars[1:]

            while len(tail) > 1:

                dummy = str(hash(slugify(tail)))

                g_new.add_rule(src, [head, dummy], False)

                src = dummy
                head = tail[0]
                tail = tail[1:]

            g_new.add_rule(src, [head, tail[0]], False)
    
    g_old = g_new
    g_new = Grammar()
    dedup = set()

    for rule in g_old.rules:

        key = slugify( [rule.src] + list(rule.tars) )

        if key not in dedup:

            g_new.add_rule(rule.src, rule.tars, rule.is_terminal)
            dedup.add(key)

    for (src, tars) in tokens.items():
        g_new.add_rule(src, tars, True)

    return g_new


class Rule:

    def __init__(self, src, tars, is_terminal):

        self.src = src
        self.tars = tars
        self.is_terminal = is_terminal

    def is_unit(self):
        return not self.is_terminal and len(self.tars) == 1

    def is_long(self):
        return not self.is_terminal and len(self.tars) > 2

    def __repr__(self):
    
        s = 'Rule('
        s += self.src
        s += ' => '

        if self.is_terminal:
            s += ' | '.join(self.tars)

        else:
            s += ' '.join(self.tars)

        s += ')'

        return s

    def has_target(self, tar):
        return not self.is_terminal and tar in self.tars

        '''
        s = 'Rule(<'
        s += self.src
        s += '>'

        nonterminals = self.get_nonterminals()
        if len(nonterminals):

            s += ' n{'
            for rule in nonterminals:
                s += '['
                s += ','.join(rule)
                s += '],'
            s += '}'

        if len(self.terminals):

            s += ' t{'
            s += ','.join(self.terminals)
            s += '}'

        s += ' p{'
        s += ','.join(self.parents)
        s += '}'

        if self.is_mixed():
            s += ' MIXED'

        if self.is_unit():
            s += ' UNIT'

        if self.is_long():
            s += ' LONG'

        s += ')'

        return s
        '''


class Grammar:

    def __init__(self):

        self.rules = []

    def add_rule(self, src, tars, is_terminal):

        rule = Rule(src, tars, is_terminal)
        self.rules.append(rule)

    def from_file(self, filepath):

        with open(filepath) as fp:

            all_tags = set()
            for line in fp:
                tag = line.split(' ')[0]
                all_tags.add(tag)

            fp.seek(0)
            for line in fp:

                line = line.strip()
                tags = line.split(' ')
                tags = [ t for t in tags if t != '|' ]

                src = tags[0]
                tars = tags[2:]

                is_terminal = True
                for tar in tars:
                    if tar in all_tags:
                        is_terminal = False

                self.add_rule(src, tars, is_terminal)

    def dedup(self):

        seen = set()
        rules = []
        tokens = defaultdict(set)

        for rule in self.rules:

            if rule.is_terminal:

                for tar in rule.tars:
                    tokens[rule.src].add(tar)

            else:

                key = hash(slugify( [rule.src] + list(rule.tars) ))

                if key not in seen:

                    rules.append(rule)
                    seen.add(key)

        for (src, tars) in tokens.items():
            rules.append(Rule(src, tars, True))

        self.rules = rules

    def print(self):

        for rule in self.rules:
            if not rule.is_terminal:

                print(rule.src, '=>', ' '.join(rule.tars))

        for rule in self.rules:
            if rule.is_terminal:

                print(rule.src, '=>', ' | '.join(rule.tars))

    def is_CNF(self):

        for rule in self.rules:
            if not rule.is_terminal and len(rule.tars) != 2:
                return False

        return True

    def __repr__(self):
        return '\n'.join([ str(r) for r in self.rules ])


class TagMap:

    def __init__(self, g):

        g = make_CNF(g)

        self.map = defaultdict(set)

        for rule in g.rules:

            if not rule.is_terminal:
   
                if len(rule.tars) != 2:
                    raise ValueError()

                key = tuple(rule.tars)
                self.map[key].add(rule.src)

    def add_lexicon(self, lexicon):

        for sent in lexicon:
            for (token, pos) in sent:

                self.map[token].add(pos)

    def save(self, filename):

        pickle.dump( self, open(filename, 'wb') )

    def load(self, filename):

        self = pickle.load( open(filename, 'rb') )

class _Grammar:
    def __init__(self):

        #self.tags = set()
        #self.token_to_POS = defaultdict(set)
        self.POS_to_token = defaultdict(set)
        #self.children_to_parent = defaultdict(set)
        self.parent_to_children = defaultdict(set)

        self.graph = defaultdict(set)

    def from_file(self, filepath):

        with open(filepath) as fp:

            # build up the list of nonterminals
            all_tags = set()
            for line in fp:
                tag = line.split(' ')[0]
                all_tags.add(tag)

            # then iterate over it again to build the grammar
            fp.seek(0)
            for line in fp:
                
                line = line.strip()
                tags = line.split(' ')

                parent_tag = tags[0]
                child_tags = tags[2:]

                is_terminal = True
                for child_tag in child_tags:
                    if child_tag in all_tags:
                        is_terminal = False

                parent = Rule(parent_tag)
                if parent_tag in self.graph:
                    parent = self.graph[parent_tag]

                if is_terminal:
                    parent.add_terminal(child_tags)
                else:
                    parent.add_nonterminal(child_tags)

                self.graph[parent_tag] = parent

            # then iterate a third time to connect children to parents
            for rule in self.graph.values():
                for nonterminal in rule.get_nonterminals():
                    for tag in nonterminal:

                        print(tag, self.graph[tag])
                        self.graph[tag].add_parent(rule.name)

    def fix(self):

        
        
        while self.has_units():
            for rule in self.graph.values():

                print()
                #print(rule)
                if rule.is_unit():
                    print(rule)

                    to_replace = rule.name
                    removed_parents = set()

                    #print('fix unit')
                    for parent in rule.parents:

                        removed_nonterminals = set()
                        parent = self.graph[parent]
                        #print('<parent>', parent)

                        for parent_nt in parent.get_nonterminals():

                            if to_replace in parent_nt:

                                removed_parents.add(parent.name)

                                for rule_nt in rule.get_nonterminals():

                                    #print('replace', to_replace, 'with', rule_nt)
                                    parent.replace_nonterminal(parent_nt, to_replace, rule_nt)

                                    for rule_tag in rule_nt:

                                        #print('rule tag', self.graph[rule_tag])

                                        if to_replace in self.graph[rule_tag].parents:
                                            self.graph[rule_tag].remove_parent(to_replace)
                                        self.graph[rule_tag].add_parent(parent.name)

                                removed_nonterminals.add( slugify(parent_nt) )

                        if parent.name in removed_parents:

                            #print('delete rules containing', rule.name, removed_nonterminals)
                            for removed_nt in removed_nonterminals:
                                parent.remove_nonterminal( deslugify(removed_nt) )

                        #print('</parent>', parent)

                    for name in removed_parents:
                        rule.remove_parent(name)

                    for rule_nt in rule.get_nonterminals():
                        rule.remove_nonterminal(rule_nt)

                    #print(rule)
                    #print()
                    self.print_rules()

                    break

        self.print()

        while self.has_long():
            for rule in self.graph.values():

                print()
                print(rule)
                if rule.is_long():

                    print('fix long')

            
        return

    def has_units(self):

        for rule in self.graph.values():
            if rule.is_unit():
                return True

        return False

    def is_CNF(self):

        if self.contains_mixed_terminals():
            return False
        if self.contains_unit_productions():
            return False
        if self.contains_long_terminals():
            return False

        return True


        all_tags = set()
        for parent in self.parent_to_children.keys():
            all_tags.add(parent)
            if self.POS_to_token[parent]:
                raise ValueError('mixed')


        for (parent, rules) in self.parent_to_children.items():

            r = Rule(parent)

            is_terminal = True
            for rule in rules:

                children = deslugify(rule)

                for child in children:

                    if child in all_tags:
                        is_terminal = False
                    elif not is_terminal:
                        raise ValueError('mixed')


                print(parent, children, is_terminal)
            print(r)

    def to_CNF(self):

        g = Grammar()

        all_tags = set()
        for parent in self.parent_to_children.keys():
            all_tags.add(parent)
            if self.POS_to_token[parent]:
                print('MIXED')

        units = defaultdict(set)
        for (parent, rules) in self.parent_to_children.items():
            for rule in rules:
                tags = deslugify(rule)
                if tags[0] in all_tags and len(tags) == 1:
                    units[parent].add(tags[0])

        print(all_tags)
        print()
        print(units)
        print()

        nonterminals = defaultdict(set)

        for (parent, rules) in self.parent_to_children.items():
            print('\n',parent,rules)
            for rule in rules:

                old_tags = deslugify(rule)
                new_tags = []

                for tag in old_tags:
                    if tag in units:
                        new_tags.append(units[tag])
                    else:
                        new_tags.append(set([tag]))
                        #print(tag, units[tag])

                print('>', new_tags)

                print('--')

                all_tags = []
                for tags in new_tags:
                    for tag in tags:
                        print(tag)

        graph = defaultdict(set)
        for parent in tags:
            for rule in self.parent_to_children[parent]:
                for child in deslugify(rule):
                    graph[parent].add(rule)

        exit(1)


        for (parent, rules) in self.parent_to_children.items():
        
            print(parent, rules)
            for rule in rules:

                tags = deslugify(rule)

                if len(tags) == 1:
                    print('UNIT')
                elif len(tags) == 2:
                    print('ok')
                else:
                    print('LONG')



    def contains_mixed_terminals(self):
   
        return False

        for (parent, children) in self.get_rules():
            for child in children:
                if True: #if child not in self.tags:
                    #print('MIXED TERMINAL', (parent, children))
                    return True

        return False

    def contains_unit_productions(self):

        for (parent, children) in self.get_rules():
            if len(children) == 1:
                #print('UNIT PRODUCTION', (parent, children))
                return True

        return False

    def fix_unit_productions(self):

        for unit_production in self.parent_to_children.keys():
               
            if True:

                unit_products = []
                
                for product in self.parent_to_children[unit_production]:
                    product = deslugify(product)
                    if len(product) == 1:
                        unit_products.append(product[0])

                RHSs = []
                for (parent, children) in self.get_rules():
                    if unit_production in children:
                        RHSs.append( (parent, children) )

                for unit_product in unit_products:

                    print('\n**', unit_production, unit_product, RHSs)

                    for (parent, children) in RHSs:
                        print('---')
                        print(parent, children)

                        # replace the unit_production with its unit_product
                        new_children = []
                        for child in children:
                            if child == unit_production:
                                new_children.append(unit_product)
                            else:
                                new_children.append(child)

                        old_children_key = slugify(children)
                        new_children_key = slugify(new_children)

                        print(old_children_key)
                        print(new_children_key)
                        print(self.parent_to_children[parent])

                        #self.parent_to_children[parent].remove(old_children_key)
                        self.parent_to_children[parent].add(new_children_key)

                    print('---')

                    '''
                    # for each appearance of the unit_production on the right
                    for (parent, children) in RHSs:
                        
                        print(parent, children)

                        # replace the unit_production with its unit_product
                        new_children = []
                        for child in children:

                            if child == unit_production:
                                new_children.append(unit_product)
                            else:
                                new_children.append(child)
                        
                        old_children_key = slugify(children)
                        new_children_key = slugify(new_children)

                        self.parent_to_children[parent].remove(old_children_key)
                        self.parent_to_children[parent].add(new_children_key)
    
                        #for parent in self.children_to_parent[old_children_key]:
                            #self.children_to_parent[new_children_key].add(parent)
                        #del self.children_to_parent[old_children_key]
                   
                    print(unit_production, unit_product)
                    print(self.parent_to_children[unit_production])
                    self.parent_to_children[unit_production].remove(unit_product)
                    if len(self.parent_to_children[unit_production]) == 0:
                        del self.parent_to_children[unit_production]
                        '''


    def contains_long_terminals(self):

        for (parent, children) in self.get_rules():
            if len(children) > 2:
                #print('LONG TERMINAL', (parent, children))
                return True

        return False


    def get_rules(self):
        
        rules = []

        for (parent, children_sets) in self.parent_to_children.items():
            for children in children_sets:
                children = deslugify(children)

                rules.append( (parent, children) )

        return rules

    def print_rules(self):

        for rule in self.graph.values():
            for nonterminal in rule.get_nonterminals():

                print(rule.name, '=>', ' '.join(nonterminal))

        
    def print_lex(self):

        for rule in self.graph.values():
            if len(rule.terminals):

                print(rule.name, '=>', ' | '.join(rule.terminals))

    def print(self):
        self.print_rules()
        self.print_lex()


def expand(to_expand, ret=[]):

    if len(to_expand) == 0:
        return [ret]

    expansions = []
    for chunk in to_expand[0]:
        expansions += expand( to_expand[1:], ret + [chunk] )

    return expansions

if __name__ == '__main__':

    parser = argparse.ArgumentParser()
    parser.add_argument('file', help='file to read in grammar from')
    args = parser.parse_args()

    grammar = Grammar()
    grammar.from_file(args.file)
    grammar = make_CNF(grammar)

    if not grammar.is_CNF():
        ValueError()
    
    grammar.print()
    exit()

    #print(grammar.is_CNF())

    #grammar.print_rules()

    grammar.fix()
    exit()

    grammar.to_CNF()

    if not grammar.is_CNF():

        if grammar.contains_unit_productions():
            grammar.fix_unit_productions()

    grammar.print_rules()
